datadog:
  apiKeyExistingSecret: datadog-secret
  pipelineId: "46dc46ba-3def-11ee-9679-da7ad0900002"
  site: "datadoghq.com"

# ## Autoscaling
# ##
# autoscaling:
#   enabled: true
#   minReplicas: 2
#   targetCPUUtilizationPercentage: 80

# podDisruptionBudget:
#   enabled: true
#   minAvailable: 1

## HorizontalPodAutoscaler (HPA) requires resource requests to function,
## so this example configures several default values. Datadog recommends
## that you change the values to match the actual size of instances that
## you are using.
resources:
  requests:
    cpu: 1000m
    memory: 512Mi

affinity:
  ## To prevent a single datacenter from causing a complete system failure,
  ## this example defaults to running pods in different availability zones.
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - observability-pipelines-worker
          topologyKey: topology.kubernetes.io/zone


## Load Balancing
## This example configuration avoids cross-availability-zone costs where possible.
service:
  enabled: true
  type: "LoadBalancer"
  loadBalancerIP: 10.0.0.209
  ipFamilies:	
    - IPv4	
## Buffering
## This creates an EBS drive that can be used for buffers, which
## must then be configured in the sinks themselves.
##
## The default drive is `io2`. Alternatively, you can also use `gp3` drives.
persistence:
  enabled: true
  storageClassName: "local-storage"
  accessModes:
    - ReadWriteOnce
  size: 10Gi


## Observability Pipelines (OP) Configuration
## This is a sample configuration that Datadog recommends for
## getting started with OP. It sets up data proxying and provides hooks
## for your own processing steps.
pipelineConfig:
  sinks:
    nr_logs:
      account_id: "4092900"
      api: logs
      buffer:
        max_size: 4294967296
        type: disk
      inputs:
        - datadog_agent.logs
      license_key: ENC[k8s_secret@newrelic/newrelic-secret/licenseKey]
      region: us
      type: new_relic
    datadog_logs:
      buffer:
        max_size: 4294967296
        type: disk
      compression: gzip
      default_api_key: ${DD_API_KEY}
      inputs:
        - logs_finish_ddtags
      site: ${DD_SITE}
      type: datadog_logs
    datadog_metrics:
      buffer:
        max_size: 4294967296
        type: disk
      default_api_key: ${DD_API_KEY}
      inputs:
        - metrics_add_dd_tags
      site: ${DD_SITE}
      type: datadog_metrics
  sources:
    datadog_agent:
      address: 0.0.0.0:8282
      multiple_outputs: true
      type: datadog_agent
  transforms:
    logs_enrich:
      inputs:
        - logs_remove_wrong_level
      source: |
        .ddtags.sender = "observability_pipelines_worker"
        .ddtags.opw_aggregator = get_hostname!()
      type: remap
    logs_finish_ddtags:
      inputs:
        - logs_enrich
      source: >
        .ddtags = encode_key_value!(.ddtags, key_value_delimiter: ":",
        field_delimiter: ",")
      type: remap
    logs_parse_ddtags:
      inputs:
        - datadog_agent.logs
      source: >
        .ddtags = parse_key_value!(.ddtags, key_value_delimiter: ":",
        field_delimiter: ",")
      type: remap
    logs_remove_wrong_level:
      inputs:
        - logs_parse_ddtags
      source: |
        del(.status)
      type: remap
    metrics_add_dd_tags:
      inputs:
        - datadog_agent.metrics
      source: |
        .tags.sender = "observability_pipelines_worker"
        .tags.opw_aggregator = get_hostname!()
      type: remap
